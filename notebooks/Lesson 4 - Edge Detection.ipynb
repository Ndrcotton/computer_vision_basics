{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, cmap = None, fig_size = (10, 10)):\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    ax.imshow(image, cmap = cmap)\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/seal.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (7, 7), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(blurred, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Simple Thresholding\n",
    "\n",
    "In simple thresholding, we manually supply our T threshold value. Any value above this value will be set to `max_val` in a binary thresholding operation or 0 for an inverse binary operation. Here we set `max_val` to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using normal thresholding (rather than inverse thresholding),\n",
    "# we can change the last argument in the function to make the coins\n",
    "# black rather than white.\n",
    "(T, thresh) = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
    "# Threshold Binary\n",
    "show_image(thresh, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, threshInv) = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "# Threshold Binary Inverse\n",
    "show_image(threshInv, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we can visualize only the masked regions in the image\n",
    "bitwise_output = cv2.bitwise_and(image, image, mask=threshInv)\n",
    "show_image(np.flip(image, axis = 2))\n",
    "show_image(np.flip(bitwise_output, axis = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Otsu's Method\n",
    "Otsu’s method assumes that our image contains two classes of pixels: the background and the foreground. Furthermore, Otsu’s method makes the assumption that the grayscale histogram of our pixel intensities of our image is bi-modal, which simply means that the histogram is two peaks.\n",
    "\n",
    "Based on the image's grayscale histogram, Otsu’s method then computes an optimal threshold value T such that the variance between the background and foreground peaks is minimal.\n",
    "\n",
    "It’s also important to note that Otsu’s method is an example of global thresholding — implying that a single value of T is computed for the entire image. In some cases, having a single value of T for an entire image is perfectly acceptable — but in other cases, this can lead to sub-par results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Otsu's automatic thresholding -- Otsu's method automatically\n",
    "# determines the best threshold value `T` for us\n",
    "(T, threshInv) = cv2.threshold(blurred, 0, 255,\n",
    "    cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "print(\"Otsu's thresholding value: {}\".format(T))\n",
    "show_image(threshInv, cmap = 'gray') # same as cv2.imshow(\"Threshold\", threshInv)\n",
    " \n",
    "# finally, we can visualize only the masked regions in the image\n",
    "bitwise_and = cv2.bitwise_and(image, image, mask=threshInv)\n",
    "show_image(bitwise_and, cmap = 'gray') # same as cv2.imshow(\"Output\", bitwise_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Adaptive Thresholding\n",
    "\n",
    "Adaptive thresholding considers small neighbors of pixels and then finds an optimal threshold value T for each neighbor. This method allows us to handle cases where there may be dramatic ranges of pixel intensities and the optimal value of T may change for different parts of the image.\n",
    "\n",
    "However, choosing the size of the pixel neighborhood for local thresholding is absolutely crucial.\n",
    "The neighborhood must be large enough to cover sufficient background and foreground pixels, otherwise the value of T will be more or less irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of manually specifying the threshold value, we can use adaptive\n",
    "# thresholding to examine neighborhoods of pixels and adaptively threshold\n",
    "# each neighborhood -- in this example, we'll calculate the mean value\n",
    "# of the neighborhood area of 25 pixels and threshold based on that value;\n",
    "# finally, our constant C is subtracted from the mean calculation (in this\n",
    "# case 15)\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255,\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 35, 5)\n",
    "show_image(thresh, cmap = 'gray') # same as cv2.imshow(\"OpenCV Mean Thresh\", thresh)\n",
    " \n",
    "# personally, I prefer the scikit-image adaptive thresholding, it just\n",
    "# feels a lot more \"Pythonic\"\n",
    "T = skimage.filters.threshold_local(blurred, 33, offset=4, method=\"gaussian\")\n",
    "thresh = (blurred < T).astype(\"uint8\") * 255\n",
    "show_image(thresh, cmap = 'gray') # cv2.imshow(\"scikit-image Mean Thresh\", thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Apply all three types of thresholding to another image - Which one has performs better for that image? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply the above three thresholding methods to another image. Which has performed better? - You may need to fine tune Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sobel and Scharr Derivatives\n",
    "The Sobel method uses two kernels for calculating gradients: one for detecting horizontal changes in direction and the other for detecting vertical changes in direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('../img/bricks.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# compute gradients along the X and Y axis, respectively\n",
    "sobelx = cv2.Sobel(gray, ddepth = cv2.CV_64F, dx=1, dy=0)\n",
    "sobely = cv2.Sobel(gray, ddepth = cv2.CV_64F, dx=0, dy=1)\n",
    "\n",
    "# the gx and gy images are now of the floating point data type\n",
    "# so we need to take care to convert them back to an unsigned 8-bit\n",
    "# integer representation so other opencv functions can utilise them\n",
    "sobelx = cv2.convertScaleAbs(sobelx)\n",
    "sobely = cv2.convertScaleAbs(sobely)\n",
    "sobel_combined = cv2.addWeighted(sobelx, 0.5, sobely, 0.5, 0)\n",
    "\n",
    "# Compute combined gradients using Laplacian Algorithm (and convert floating values to ints)\n",
    "laplacian = cv2.Laplacian(gray,cv2.CV_64F)\n",
    "laplacian = cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,3,1),plt.imshow(gray,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,3,2),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,3,3),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,3,4),plt.imshow(sobel_combined,cmap = 'gray')\n",
    "plt.title('Sobel Combined'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,3,5),plt.imshow(laplacian,cmap = 'gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Output Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/bricks.png',0)[0:200, 0:200]\n",
    "\n",
    "# Output dtype = cv2.CV_8U\n",
    "sobelx8u = cv2.Sobel(img,cv2.CV_8U,1,0)\n",
    "\n",
    "# Output dtype = cv2.CV_64F. Then take its absolute and convert to cv2.CV_8U\n",
    "sobelx64f = cv2.Sobel(img,cv2.CV_64F,1,0)\n",
    "abs_sobel64f = np.absolute(sobelx64f)\n",
    "sobel_8u = np.uint8(abs_sobel64f)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,2),plt.imshow(sobelx8u,cmap = 'gray')\n",
    "plt.title('Sobel CV_8U'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,3),plt.imshow(sobel_8u,cmap = 'gray')\n",
    "plt.title('Sobel abs(CV_64F)'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Gradient Orientation and Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/bricks.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# compute gradients along the X and Y axis, respectively\n",
    "gX = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "gY = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    " \n",
    "# compute the gradient magnitude and orientation respectively\n",
    "mag = np.sqrt((gX ** 2) + (gY ** 2))\n",
    "orientation = np.arctan2(gY, gX) * (180 / np.pi) % 180\n",
    "\n",
    "# Printing magnitude and orientation at pixel (100, 100)\n",
    "print('Magnitude at pixel (100, 100):', mag[100, 100])\n",
    "print('Orientation at pixel (100, 100):', orientation[100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Detecting Gradient Changes using Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_angle = 90\n",
    "upper_angle = 100\n",
    "\n",
    "# find all pixels that are within the upper and low angle boundaries\n",
    "idxs = np.where(orientation >= lower_angle, orientation, -1)\n",
    "idxs = np.where(orientation <= upper_angle, idxs, -1)\n",
    "mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "mask[idxs > -1] = 255\n",
    " \n",
    "# show the images\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1),plt.imshow(gray,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2),plt.imshow(mask,cmap = 'gray')\n",
    "plt.title('Mask'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Calculating Orientation and Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the seal image and calculate the gradient orientation and magnitude of the image at pixel 100, 100\n",
    "img = cv2.imread('../img/seal.png')\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ../solutions/gradient_seal.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"../img/bricks.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 10, 250)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121),plt.imshow(gray,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Canny Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tuning Edge Detection Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image, convert it to grayscale, and blur it slightly\n",
    "image = cv2.imread('../img/bricks.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "# compute a \"wide\", \"mid-range\", and \"tight\" threshold for the edges\n",
    "wide = cv2.Canny(blurred, 10, 200)\n",
    "mid = cv2.Canny(blurred, 30, 150)\n",
    "tight = cv2.Canny(blurred, 240, 250)\n",
    " \n",
    "# show the edge maps\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(221),plt.imshow(blurred,cmap = 'gray')\n",
    "plt.title('Blurred Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(222),plt.imshow(wide,cmap = 'gray')\n",
    "plt.title('Wide Edge Map'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(223),plt.imshow(mid,cmap = 'gray')\n",
    "plt.title('Mid Edge Map'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(224),plt.imshow(tight,cmap = 'gray')\n",
    "plt.title('Tight Edge Map'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Apply Canny Edge detection to the license plate image. Fine tune the upper and lower limit Threshold values. What are these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/license_plate.png')\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "%load ../solutions/canny_license_plate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Auto-Tuning Edge Detection Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    " \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "    # return the edged image\n",
    "    return edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto_canny(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "show_image(auto, cmap = 'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
