{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, cmap = None, fig_size = (10, 10)):\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    ax.imshow(image, cmap = cmap)\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(args[\"image\"])\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (7, 7), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, threshInv) = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Threshold Binary Inverse\", threshInv)\n",
    " \n",
    "# using normal thresholding (rather than inverse thresholding),\n",
    "# we can change the last argument in the function to make the coins\n",
    "# black rather than white.\n",
    "(T, thresh) = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Threshold Binary\", thresh)\n",
    " \n",
    "# finally, we can visualize only the masked regions in the image\n",
    "cv2.imshow(\"Output\", cv2.bitwise_and(image, image, mask=threshInv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Otsu's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Otsu's automatic thresholding -- Otsu's method automatically\n",
    "# determines the best threshold value `T` for us\n",
    "(T, threshInv) = cv2.threshold(blurred, 0, 255,\n",
    "    cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Threshold\", threshInv)\n",
    "print(\"Otsu's thresholding value: {}\".format(T))\n",
    " \n",
    "# finally, we can visualize only the masked regions in the image\n",
    "cv2.imshow(\"Output\", cv2.bitwise_and(image, image, mask=threshInv))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of manually specifying the threshold value, we can use adaptive\n",
    "# thresholding to examine neighborhoods of pixels and adaptively threshold\n",
    "# each neighborhood -- in this example, we'll calculate the mean value\n",
    "# of the neighborhood area of 25 pixels and threshold based on that value;\n",
    "# finally, our constant C is subtracted from the mean calculation (in this\n",
    "# case 15)\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255,\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 25, 15)\n",
    "cv2.imshow(\"OpenCV Mean Thresh\", thresh)\n",
    " \n",
    "# personally, I prefer the scikit-image adaptive thresholding, it just\n",
    "# feels a lot more \"Pythonic\"\n",
    "T = threshold_local(blurred, 29, offset=5, method=\"gaussian\")\n",
    "thresh = (blurred < T).astype(\"uint8\") * 255\n",
    "cv2.imshow(\"scikit-image Mean Thresh\", thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Apply all three types of thresholding to an image - Which one has performmed better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sobel and Scharr Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dave.jpg',0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Output Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('box.png',0)\n",
    "\n",
    "# Output dtype = cv2.CV_8U\n",
    "sobelx8u = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=5)\n",
    "\n",
    "# Output dtype = cv2.CV_64F. Then take its absolute and convert to cv2.CV_8U\n",
    "sobelx64f = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "abs_sobel64f = np.absolute(sobelx64f)\n",
    "sobel_8u = np.uint8(abs_sobel64f)\n",
    "\n",
    "plt.subplot(1,3,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,2),plt.imshow(sobelx8u,cmap = 'gray')\n",
    "plt.title('Sobel CV_8U'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,3),plt.imshow(sobel_8u,cmap = 'gray')\n",
    "plt.title('Sobel abs(CV_64F)'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Apply both kernels to an image - Which one has performmed better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Gradient Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradients along the X and Y axis, respectively\n",
    "gX = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "gY = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    " \n",
    "# compute the gradient magnitude and orientation respectively\n",
    "mag = np.sqrt((gX ** 2) + (gY ** 2))\n",
    "mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Gradient Oreintation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation = np.arctan2(gY, gX) * (180 / np.pi) % 180\n",
    "\n",
    "# find all pixels that are within the upper and low angle boundaries\n",
    "idxs = np.where(orientation >= args[\"lower_angle\"], orientation, -1)\n",
    "idxs = np.where(orientation <= args[\"upper_angle\"], idxs, -1)\n",
    "mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "mask[idxs > -1] = 255\n",
    " \n",
    "# show the images\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Calculating Orientation and Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('messi5.jpg',0)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tuning Edge Detection Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image, convert it to grayscale, and blur it slightly\n",
    "image = cv2.imread(args[\"image\"])\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    " \n",
    "# show the original and blurred images\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Blurred\", blurred)\n",
    " \n",
    "# compute a \"wide\", \"mid-range\", and \"tight\" threshold for the edges\n",
    "wide = cv2.Canny(blurred, 10, 200)\n",
    "mid = cv2.Canny(blurred, 30, 150)\n",
    "tight = cv2.Canny(blurred, 240, 250)\n",
    " \n",
    "# show the edge maps\n",
    "cv2.imshow(\"Wide Edge Map\", wide)\n",
    "cv2.imshow(\"Mid Edge Map\", mid)\n",
    "cv2.imshow(\"Tight Edge Map\", tight)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    " \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "    # return the edged image\n",
    "    return edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto_canny(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "cv2.imshow(\"Auto\", auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Apply both kernels to an image - Which one has performmed better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
