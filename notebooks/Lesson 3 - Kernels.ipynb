{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, cmap = None, fig_size = (10, 10)):\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    ax.imshow(image, cmap = cmap)\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Constructing a Kernel\n",
    "OpenCV provides a function, cv2.filter2D(), to convolve a kernel with an image. As an example, we will try an averaging filter on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/tictactoe.png')\n",
    "\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Structual Elements (Kernel Shapes)\n",
    "In some cases, you may need elliptical/circular shaped kernels. So for this purpose, OpenCV has a function, cv2.getStructuringElement(). You just pass the shape and size of the kernel, you get the desired kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Smoothing Kernels\n",
    "Image blurring is achieved by convolving the image with a low-pass filter kernel. It is useful for removing noise. It actually removes high frequency content (e.g: noise, edges) from the image resulting in edges being blurred when this is filter is applied. (Well, there are blurring techniques which do not blur edges). OpenCV provides mainly four types of blurring techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Average Blurring\n",
    "This is done by convolving the image with a normalized box filter. It simply takes the average of all the pixels under kernel area and replaces the central element with this average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/lego.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernelSizes = [(3, 3), (9, 9), (15, 15)]\n",
    " \n",
    "# loop over the kernel sizes and apply an \"average\" blur to the image\n",
    "for i, (kX, kY) in enumerate(kernelSizes):\n",
    "    blurred = cv2.blur(gray, (kX, kY))\n",
    "    plt.subplot(2,2,i+2),plt.imshow(blurred, cmap = 'gray')\n",
    "    plt.title(f\"Average ({kX}, {kY})\"), plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Gaussian Blurring\n",
    "In this approach, instead of a box filter consisting of equal filter coefficients, a Gaussian kernel is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/lego.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernelSizes = [(3, 3), (9, 9), (15, 15)]\n",
    " \n",
    "# loop over the kernel sizes and apply an \"average\" blur to the image\n",
    "for i, (kX, kY) in enumerate(kernelSizes):\n",
    "    blurred = cv2.GaussianBlur(gray, (kX, kY), 0)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(blurred, cmap = 'gray')\n",
    "    plt.title(f\"Gaussian ({kX}, {kY})\"), plt.xticks([]), plt.yticks([])### 3.3 Median Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Median Blurring\n",
    "Here, the function `cv2.medianBlur()` computes the median of all the pixels under the kernel window and the central pixel is replaced with this median value. This is highly effective in removing salt-and-pepper noise. Median blur method has been most effective when removing salt-and-pepper noise. unlike average blurring and Gaussian blurring where the kernel size could be rectangular, the kernel size for the median must be square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/lego.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernel_sizes = [3, 9, 15]\n",
    " \n",
    "# loop over the kernel sizes and apply an \"average\" blur to the image\n",
    "for i, k in enumerate(kernel_sizes):\n",
    "    blurred = cv2.medianBlur(gray, k)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(blurred, cmap = 'gray')\n",
    "    plt.title(f\"Median ({k})\"), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Bi-lateral Blurring\n",
    "In order to reduce noise while still maintaining edges, we can use bilateral blurring. bilateral blurring accomplishes this by introducing two Gaussian distributions. The first Gaussian function only considers spatial neighbors.  That is, pixels that appear close together in the (x, y)-coordinate space of the image. The second Gaussian then models the pixel intensity  of the neighborhood, ensuring that only pixels with similar intensity are included in the actual computation of the blur.\n",
    "\n",
    "This method is able to preserve edges of an image,  while still reducing noise. The largest downside to this method is  that it is considerably slower than its averaging, Gaussian, and median blurring counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/lego.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "params = [(11, 21, 7), (11, 41, 21), (11, 61, 39)]\n",
    "\n",
    "# loop over the diameter, sigma color, and sigma space\n",
    "for i, (diameter, sigma_colour, sigma_space) in enumerate(params):\n",
    "    blurred = cv2.medianBlur(gray, k)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(blurred, cmap = 'gray')\n",
    "    plt.title(f\"Blurred d={diameter}, sc={sigma_colour}, ss={sigma_space}\"), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Morphological Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Erosion\n",
    "The basic idea of erosion is just like soil erosion only, it erodes away the boundaries of foreground object (Always try to keep foreground in white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/tictactoe.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "# apply a series of erosions\n",
    "for i in range(0, 3):\n",
    "    eroded = cv2.erode(gray.copy(), None, iterations=i + 1)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(eroded, cmap = 'gray')\n",
    "    plt.title(f'Eroded {i + 1} times'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Dilation\n",
    "It is just opposite of erosion. Here, a pixel element is ‘1’ if atleast one pixel under the kernel is ‘1’. So it increases the white region in the image or size of foreground object increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/tictactoe.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "# apply a series of dilations\n",
    "for i in range(0, 3):\n",
    "    dilated = cv2.dilate(gray.copy(), None, iterations=i + 1)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(dilated, cmap = 'gray')\n",
    "    plt.title(f'Dilated {i + 1} times'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Opening\n",
    "Opening is just another name of erosion followed by dilation. It is useful in removing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/snowy_i.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernel_sizes = [(1, 1), (3, 3), (5, 5)]\n",
    " \n",
    "# loop over the kernels and apply an \"opening\" operation to the image\n",
    "for i, kernel_size in enumerate(kernel_sizes):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(opening, cmap = 'gray')\n",
    "    plt.title(f\"Opening: ({kernel_size[0]}, {kernel_size[1]})\"), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Closing\n",
    "Closing is reverse of Opening, Dilation followed by Erosion. It is useful in closing small holes inside the foreground objects, or small black points on the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/dotted_i.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernel_sizes = [(3, 3), (5, 5), (7, 7)]\n",
    " \n",
    "# loop over the kernels and apply an \"opening\" operation to the image\n",
    "for i, kernel_size in enumerate(kernel_sizes):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    closing = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(closing, cmap = 'gray')\n",
    "    plt.title(f\"Closing: ({kernel_size[0]}, {kernel_size[1]})\"), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Morphological Gradient\n",
    "It is the difference between dilation and erosion of an image.\n",
    "The result will look like the outline of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/tictactoe.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernel_sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "\n",
    "# loop over the kernels and apply a \"Morphological gradient\" operation to the image\n",
    "for i, kernel_size in enumerate(kernel_sizes):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(gradient, cmap = 'gray')\n",
    "    plt.title(f\"Morphological Gradient: ({kernel_size[0]}, {kernel_size[1]})\"), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Top Hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the difference between the closing of the input image and input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/tictactoe.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernel_sizes = [(5, 5), (8, 8), (11, 11)]\n",
    "\n",
    "# loop over the kernels and apply a \"closing\" operation to the image\n",
    "for i, kernel_size in enumerate(kernel_sizes):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    black_hat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(black_hat, cmap = 'gray')\n",
    "    plt.title(f\"Black Hat: ({kernel_size[0]}, {kernel_size[1]})\"), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 White Hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the difference between input image and Opening of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../img/tictactoe.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1),plt.imshow(gray, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "kernel_sizes = [(5, 5), (8, 8), (11, 11)]\n",
    "\n",
    "# loop over the kernels and apply a \"closing\" operation to the image\n",
    "for i, kernel_size in enumerate(kernel_sizes):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    white_hat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n",
    "    plt.subplot(2,2,i+2),plt.imshow(white_hat, cmap = 'gray')\n",
    "    plt.title(f\"Black Hat: ({kernel_size[0]}, {kernel_size[1]})\"), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOMEWORK: Use different types of structuring Elements when performing opening, closing, white and black hat operations. \n",
    "What do you notice? Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your Code Below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
